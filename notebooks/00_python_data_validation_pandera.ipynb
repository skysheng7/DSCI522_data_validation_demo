{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Python Data Validation: Pandera\"\n",
    "---\n",
    "\n",
    "## Introduction to Python's Pandera\n",
    "\n",
    "Python's [Pandera](https://pandera.readthedocs.io/en/stable/) is a package\n",
    "designed to make data validation/checking of dataframes and other dataframe-like\n",
    "objects easy, readable and robust. Key features of Pandera that we will discuss include:\n",
    "\n",
    "- The ability to define a data schema and use it to validate dataframes and other dataframe-like\n",
    "objects\n",
    "- Check the types and properties of columns\n",
    "- Perform statistical validation of data\n",
    "- Execute all validation in a lazy manner, so that validation rules are executed before raising an error\n",
    "- Handle invalid data in a number of ways, including throwing errors, writing data validation logs, and dropping observations that are invalid\n",
    "\n",
    "### Validating data with Pandera\n",
    "\n",
    "In the simplest use case,\n",
    "Pandera can be use to validate data\n",
    "by first defining an instance of the `DataFrameSchema` class.\n",
    "This object specifies the properties we expect (and thus would like to check)\n",
    "for our dataframe index and columns.\n",
    "After the `DataFrameSchema` instance has been created and defined,\n",
    "the `DataFrameSchema.validate` method\n",
    "can be applied to a `pandas.DataFrame` instance to validate, or check,\n",
    "all of the properties we specified that we expect for our dataframe index\n",
    "and columns in the `DataFrameSchema` instance.\n",
    "\n",
    "### Dataframe Schema\n",
    "\n",
    "When we create an instance of the `DataFrameSchema` class,\n",
    "we can specify the the properties we expect (and thus would like to check)\n",
    "for our dataframe index and columns.\n",
    "\n",
    "#### Creating `pa.DataFrameSchema` and setting required columns\n",
    "\n",
    "To create an instance of the `DataFrameSchema` class\n",
    "we first import the Pandera package using the alias `pa`,\n",
    "and then the function `pa.DataFrameSchema`.\n",
    "Below we demonstrate creating an instance of the `DataFrameSchema` class\n",
    "for the first two columns of the\n",
    "[Wisconsin Breast Cancer data set](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic)\n",
    "from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/)\n",
    "(Dua and Graff 2017)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandera as pa\n",
    "\n",
    "\n",
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"class\": pa.Column(),\n",
    "        \"mean_radius\": pa.Column()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ⚠️ By default all columns listed\n",
    "are required to be in the dataframe for it to pass validation.\n",
    "If we wanted to make a column optional,\n",
    "we would set `required=False` in the column constructor.\n",
    "\n",
    "#### Specifying column types\n",
    "\n",
    "We can specify the type we expect each column to be,\n",
    "by writing the type as the first argument to `pa.Column`.\n",
    "Possible values include:\n",
    "\n",
    "- a string alias, as long as it is recognized by pandas.\n",
    "- a python type: `int`, `float`, `double`, `bool`, `str`\n",
    "- a `numpy` data type\n",
    "-  a pandas extension type: it can be an instance (e.g `pd.CategoricalDtype([\"a\", \"b\"])`) or a class (e.g `pandas.CategoricalDtype`) if it can be initialized with default values.\n",
    "- a pandera `DataType`: it can also be an instance or a class.\n",
    "\n",
    "See the Pandera\n",
    "[Data Type Validation docs](https://pandera.readthedocs.io/en/stable/dtype_validation.html#dtype-validation)\n",
    "for details beyond what we present here.\n",
    "\n",
    "If we continue our example from above,\n",
    "we can specify that we expect the `class` column to be a string\n",
    "and the `mean_radius` column to be a float as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"class\": pa.Column(str),\n",
    "        \"mean_radius\": pa.Column(float)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missingness/null values\n",
    "\n",
    "By default Column objects assume there should be no null/missing values.\n",
    "If you want to allow missing values,\n",
    "you need to set `nullable=True` in the column constructor.\n",
    "We demonstrate that below for the `mean_radius` column of our working example.\n",
    "Note that we do not set this to be true for our class column\n",
    "as we likely do not want to be working with observations\n",
    "where the target/response variable is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"class\": pa.Column(str),\n",
    "        \"mean_radius\": pa.Column(float, nullable=True)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanted to allow a percentage of the values for a particular column\n",
    "to be allowed to be missing,\n",
    "then you could do this by writing a lambda function in a call to `pa.Check`\n",
    "in the column constructor.\n",
    "We show an example of that below\n",
    "where allow up to 5% of the `mean_radius` column values to be missing.\n",
    "\n",
    "> ⚠️ This is putting the cart a bit before the horse here,\n",
    "as we have not yet introduced `pa.Check`.\n",
    "We will do that in the next section,\n",
    "so please fell free to skip this\n",
    "and come back to this example after you have read that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"class\": pa.Column(str),\n",
    "        \"mean_radius\": pa.Column(float,\n",
    "                                pa.Check(lambda s: s.isna().mean() <= 0.05,\n",
    "                                    element_wise=False,\n",
    "                                    error=\"Too many null values in 'mean_radius' column.\"),\n",
    "                                nullable=True)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ⚠️ Above we have created our custom check on-the-fly using a `lambda` function.\n",
    "We could do this here because the check was fairly simple.\n",
    "If we needed a custom check that was more complex\n",
    "(e.g., needs to generate data as part of the check)\n",
    "then we would be better to register our custom check.\n",
    "For situations like this, we direct the reader to the\n",
    "[Pandera Extension docs](https://pandera.readthedocs.io/en/stable/extensions.html#extensions).\n",
    "\n",
    "#### Checking values in columns\n",
    "\n",
    "Pandera has a function `pa.Check` that is useful for checking values within columns.\n",
    "For any type of data,\n",
    "there is usually some reasonable range of values that we would expect.\n",
    "These usually come from domain knowledge about the data.\n",
    "For example,\n",
    "a column named `age` for a data set about adult human patients age in years\n",
    "should probably be an integer and have a range of values between 18 and 122\n",
    "([the oldest person whose age has ever been independently verified](https://en.wikipedia.org/wiki/List_of_the_verified_oldest_people#cite_note-5)).\n",
    "To specify a check for a range like this,\n",
    "we can use the `pa.Check.between` method.\n",
    "We demonstrate how to do this below with our working example\n",
    "to check that the `mean_radius` values are between 5 and 45, inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"class\": pa.Column(str),\n",
    "        \"mean_radius\": pa.Column(float, pa.Check.between(5, 45), nullable=True)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What if I want to do multiple checks for the same column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"class\": pa.Column(str, pa.Check.isin([\"Benign\", \"Malignant\"])),\n",
    "        \"mean_radius\": pa.Column(\n",
    "            float,\n",
    "            checks=[\n",
    "                pa.Check(lambda s: s.isna().mean() <= 0.05,\n",
    "                        element_wise=False,\n",
    "                        error=\"Too many null values in 'mean_radius' column.\"),\n",
    "                pa.Check.between(5, 45)\n",
    "            ],\n",
    "            nullable=True\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our working example,\n",
    "we might also want to check that the `class` column only contains\n",
    "the strings we think are acceptable for our category label,\n",
    "which would be `\"Benign\"` and `\"Malignant\"`.\n",
    "We can do this using the `pa.Check.isin` method, which we demonstrate below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"class\": pa.Column(str, pa.Check.isin([\"Benign\", \"Malignant\"])),\n",
    "        \"mean_radius\": pa.Column(float, pa.Check.between(5, 45), nullable=True)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more built-in `pa.Check` methods. A list can be found in the Pandera `Check` API docs:\n",
    "- <https://pandera.readthedocs.io/en/stable/reference/generated/pandera.api.checks.Check.html#pandera.api.checks.Check>\n",
    "\n",
    "If there is a check you wish to do that is not part of the Pandera `Check` API\n",
    "you have two options:\n",
    "\n",
    "1) Use a `lambda` function with boolean logic inside of `pa.Check` (good for simple checks, similar to the percentage of missingness in the section above), or\n",
    "2) Register our custom check (see how to in [Pandera Extension docs](https://pandera.readthedocs.io/en/stable/extensions.html#extensions))\n",
    "\n",
    "#### Duplicates\n",
    "\n",
    "Pandera does not yet have a method to check for duplicate rows in a dataframe,\n",
    "however, you can apply `pa.Check` to the entire data frame\n",
    "using a `lambda` function with boolean logic.\n",
    "Thus, we can easily apply Pandas `duplicated` function\n",
    "in a Lambda Function to check for duplicate rows.\n",
    "We show an example of that below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"class\": pa.Column(str, pa.Check.isin([\"Benign\", \"Malignant\"])),\n",
    "        \"mean_radius\": pa.Column(float, pa.Check.between(5, 45), nullable=True)\n",
    "    },\n",
    "    checks=[\n",
    "        pa.Check(lambda df: ~df.duplicated().any(), error=\"Duplicate rows found.\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Empty observations\n",
    "\n",
    "Similar to duplicates, there is no Pandera function for this.\n",
    "So again we can use `pa.Check` applied to the entire data frame\n",
    "using a `lambda` function with boolean logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"class\": pa.Column(str, pa.Check.isin([\"Benign\", \"Malignant\"])),\n",
    "        \"mean_radius\": pa.Column(float, pa.Check.between(5, 45), nullable=True)\n",
    "    },\n",
    "    checks=[\n",
    "        pa.Check(lambda df: ~df.duplicated().any(), error=\"Duplicate rows found.\"),\n",
    "        pa.Check(lambda df: ~(df.isna().all(axis=1)).any(), error=\"Empty rows found.\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data validation\n",
    "\n",
    "Once we have specified our the properties we expect\n",
    "(and thus would like to check)\n",
    "for our dataframe index and columns\n",
    "by creating an instance of `pa.DataFrameSchema`,\n",
    "we can use the `pa.DataFrameSchema.validate` method on a dataframe\n",
    "to check if the dataframe is valid considering the schema we specified.\n",
    "\n",
    "To demonstrate this,\n",
    "below we create two very simple versions of the Wisconsin Breast Cancer data set.\n",
    "One which we expect to pass our validation checks,\n",
    "and one where we introduce three data anomalies\n",
    "that should cause some checks to fail.\n",
    "\n",
    "First we create two data frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "valid_data = pd.DataFrame({\n",
    "    \"class\": [\"Benign\", \"Benign\", \"Malignant\"],\n",
    "    \"mean_radius\": [6.0, 31.2, 22.8]\n",
    "})\n",
    "\n",
    "invalid_data = pd.DataFrame({\n",
    "    \"class\": [\"Benign\", \"Benign\", \"benign\", \"Malignant\"],\n",
    "    \"mean_radius\": [6.0, 6.0, 31.2, -9999]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens when we apply `pa.DataFrameSchema.validate`\n",
    "to our valid data:\n",
    "\n",
    "<!-- TODO: should not need to error true this line, but trying to fix CI-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "schema.validate(valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It returns a dataframe and does not throw an error. Excellent!\n",
    "What happens when we pass clearly invalid data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "schema.validate(invalid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that's a lot, but what is clear is that an error was thrown.\n",
    "If we read through the error message to the end we see the important,\n",
    "and useful piece of the error message:\n",
    "\n",
    "```\n",
    "pandera.errors.SchemaError: Column 'class' failed element-wise validator number 0: isin(['Benign', 'Malignant']) failure cases: benign\n",
    "```\n",
    "\n",
    "The error arose because in our `invalid_data`,\n",
    "the column `class` contained the string `\"benign\"`,\n",
    "and we specified in our `pa.DataFrameSchema` instance\n",
    "that we only accept two string values in the `class` column,\n",
    "`\"Benign\"` and `\"Malignant\"`.\n",
    "\n",
    "What about the other errors we expect from our invalid data?\n",
    "For example, we there's a value of `-9999` in the `mean_radius` column\n",
    "that is well outside of the range we said was valid in the schema (5, 45),\n",
    "and we have a duplicate row as well?\n",
    "Why are these validation errors not reported?\n",
    "Pandera's default is to throw an error\n",
    "after the first instance of non-valid data.\n",
    "To change this behaviour, we can set `lazy=True`.\n",
    "When we do this we see that all errors get reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "schema.validate(invalid_data, lazy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling invalid data\n",
    "\n",
    "By default Pandera will throw an error when a check is not passed.\n",
    "Depending on your situation, this can be a desired expected behaviour\n",
    "(e.g., a static data analysis published in a report)\n",
    "or a very undesired behaviour\n",
    "that could potentially be dangerous (e.g., autonomous driving application).\n",
    "In the latter case, we would want to do something different than throw an error.\n",
    "Possibilities we will cover here include dropping invalid observations\n",
    "and writing log files that report the errors.\n",
    "\n",
    "### Dropping invalid observations\n",
    "\n",
    "In an in-production system,\n",
    "dropping non-valid data could be a reasonable path forward\n",
    "instead of throwing an error.\n",
    "Another situation where this might be a reasonable thing to do\n",
    "is when training a machine learning model with a million observations.\n",
    "You don't want to throw an error in the middle of training\n",
    "if only one observation is invalid!\n",
    "\n",
    "To change the behaviour of `pa.DataFrameSchema.validate`\n",
    "to instead return a dataframe with the invalid rows dropped\n",
    "we need to do two things:\n",
    "\n",
    "1. add `drop_invalid_rows=True` to our  `pa.DataFrameSchema` instance\n",
    "2. add `lazy=True` to our call to the `pa.DataFrameSchema.validate` method\n",
    "\n",
    "Below we demonstrate this with our working example.\n",
    "\n",
    "<!-- TODO: should not need to error true this line, but trying to fix CI-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"class\": pa.Column(str, pa.Check.isin([\"Benign\", \"Malignant\"]), nullable=True),\n",
    "        \"mean_radius\": pa.Column(float, pa.Check.between(5, 45), nullable=True)\n",
    "    },\n",
    "    checks=[\n",
    "        pa.Check(lambda df: ~df.duplicated().any(), error=\"Duplicate rows found.\"),\n",
    "        pa.Check(lambda df: ~(df.isna().all(axis=1)).any(), error=\"Empty rows found.\")\n",
    "    ],\n",
    "    drop_invalid_rows=True\n",
    ")\n",
    "\n",
    "schema.validate(invalid_data, lazy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm... Why did the duplicate row sneak through? This is because Pandera's\n",
    "dropping rows only works on data, or column, checks,\n",
    "not the DataFrame-wide checks like our checks for duplicates or empty rows.\n",
    "Thus to make sure we drop these, we need to rely on Pandas to do this.\n",
    "We demonstrate how we can do this below:\n",
    "\n",
    "<!-- TODO: should not need to error true this line, but trying to fix CI-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | error: true\n",
    "schema.validate(invalid_data, lazy=True).drop_duplicates().dropna(how=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing data validation logs\n",
    "\n",
    "Is removing the rows sufficient? Not at all!\n",
    "A human should be told that there was invalid data\n",
    "so that upstream data collection, cleaning and transformation processes\n",
    "can be reviewed to minimize the chances of future invalid data.\n",
    "One way to do this is to again specify `lazy=True`\n",
    "so that all errors can be observed and reported.\n",
    "Then we can get the `SchemaErrors` and write them to a log file.\n",
    "We show below how to do this for our working example\n",
    "so that the valid rows are returned as a dataframe named `validated_data`\n",
    "and the errors are logged as a file called `validation_errors.log`:\n",
    "\n",
    "<!-- TODO: should not need to error true this line, but trying to fix CI-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | error: true\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import pandera as pa\n",
    "from pandera import Check\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=\"validation_errors.log\",\n",
    "    filemode=\"w\",\n",
    "    format=\"%(asctime)s - %(message)s\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "\n",
    "# Define the schema\n",
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"class\": pa.Column(str, pa.Check.isin([\"Benign\", \"Malignant\"]), nullable=True),\n",
    "        \"mean_radius\": pa.Column(float, pa.Check.between(5, 45), nullable=True),\n",
    "    },\n",
    "    checks=[\n",
    "        pa.Check(lambda df: ~df.duplicated().any(), error=\"Duplicate rows found.\"),\n",
    "        pa.Check(lambda df: ~(df.isna().all(axis=1)).any(), error=\"Empty rows found.\"),\n",
    "    ],\n",
    "    drop_invalid_rows=False,\n",
    ")\n",
    "\n",
    "# Initialize error cases DataFrame\n",
    "error_cases = pd.DataFrame()\n",
    "data = invalid_data.copy()\n",
    "\n",
    "# Validate data and handle errors\n",
    "try:\n",
    "    validated_data = schema.validate(data, lazy=True)\n",
    "except pa.errors.SchemaErrors as e:\n",
    "    error_cases = e.failure_cases\n",
    "\n",
    "    # Convert the error message to a JSON string\n",
    "    error_message = json.dumps(e.message, indent=2)\n",
    "    logging.error(\"\\n\" + error_message)\n",
    "\n",
    "# Filter out invalid rows based on the error cases\n",
    "if not error_cases.empty:\n",
    "    invalid_indices = error_cases[\"index\"].dropna().unique()\n",
    "    validated_data = (\n",
    "        data.drop(index=invalid_indices)\n",
    "        .reset_index(drop=True)\n",
    "        .drop_duplicates()\n",
    "        .dropna(how=\"all\")\n",
    "    )\n",
    "else:\n",
    "    validated_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
